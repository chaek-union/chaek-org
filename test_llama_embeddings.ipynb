{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama.cpp Embeddings Test\n",
    "\n",
    "This notebook tests the llama.cpp server embeddings endpoint running in Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the llama.cpp server endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running from host machine\n",
    "LLAMA_SERVER_URL = \"http://localhost:8080\"\n",
    "\n",
    "# For running from inside Docker network, use:\n",
    "# LLAMA_SERVER_URL = \"http://llama:8080\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Simple Embedding Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str):\n",
    "    \"\"\"Get embedding vector for given text\"\"\"\n",
    "    response = requests.post(\n",
    "        f\"{LLAMA_SERVER_URL}/embedding\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        json={\"input\": text}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "# Test with simple text\n",
    "result = get_embedding(\"Hello embeddings\")\n",
    "print(\"Response keys:\", result.keys())\n",
    "print(\"Embedding dimension:\", len(result.get('embedding', [])))\n",
    "print(\"First 10 values:\", result.get('embedding', [])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Multiple Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Hello embeddings\",\n",
    "    \"Natural language processing\",\n",
    "    \"Machine learning models\",\n",
    "    \"Vector databases\"\n",
    "]\n",
    "\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    result = get_embedding(text)\n",
    "    embeddings.append(result.get('embedding', []))\n",
    "    print(f\"Text: '{text}' -> Embedding dim: {len(result.get('embedding', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Cosine Similarity\n",
    "\n",
    "Calculate similarity between embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Compare all pairs\n",
    "print(\"Similarity matrix:\")\n",
    "print(f\"{'':30s}\", end=\"\")\n",
    "for t in texts:\n",
    "    print(f\"{t[:15]:15s}\", end=\" \")\n",
    "print()\n",
    "\n",
    "for i, text1 in enumerate(texts):\n",
    "    print(f\"{text1:30s}\", end=\"\")\n",
    "    for j, text2 in enumerate(texts):\n",
    "        similarity = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"{similarity:15.4f}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Server Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check server health\n",
    "health_response = requests.get(f\"{LLAMA_SERVER_URL}/health\")\n",
    "print(\"Health status:\", health_response.status_code)\n",
    "print(\"Response:\", health_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Using curl (shell command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl --request POST \\\n",
    "    --url http://localhost:8080/embedding \\\n",
    "    --header \"Content-Type: application/json\" \\\n",
    "    --data '{\"input\": \"Hello embeddings\"}' \\\n",
    "    --silent | jq '.embedding | length'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
